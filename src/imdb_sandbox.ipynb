{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import locale\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "import pylab as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inspired by:\\nhttps://gist.github.com/zacstewart/5978000\\nhttps://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb\\n\\ndata description:\\nhttp://ai.stanford.edu/~amaas/data/sentiment/\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"inspired by:\n",
    "https://gist.github.com/zacstewart/5978000\n",
    "https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb\n",
    "\n",
    "data description:\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Load and pre-format reviews\"\n",
    "# locale.setlocale(locale.LC_ALL, 'C')\n",
    "\n",
    "\n",
    "# Convert text to lower-case and strip punctuation/symbols from words\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        norm_text = norm_text.replace(char, ' ' + char + ' ')\n",
    "\n",
    "    return norm_text\n",
    "\n",
    "\n",
    "def collect_reviews(datadirname = \"../data/\"):\n",
    "    filename = os.path.join(datadirname, 'aclImdb_v1.tar.gz')\n",
    "    dirname = filename.replace(\"_v1.tar.gz\", \"\")\n",
    "    if not os.path.isdir(dirname):\n",
    "        if not os.path.isfile(filename):\n",
    "            print(\"file 'alldata-id.txt' not found; downloading\")\n",
    "            # Download IMDB archive\n",
    "            url = 'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "            r = requests.get(url)\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        print(\"directory '%s' not found; extracting\" % dirname)\n",
    "        tar = tarfile.open(filename, mode='r')\n",
    "        tar.extractall(path=datadirname)\n",
    "        tar.close()\n",
    "\n",
    "    # Concat and normalize test/train data\n",
    "    folders = ['train/pos', 'train/neg', 'test/pos', 'test/neg', 'train/unsup']\n",
    "    #     alldata = u''\n",
    "    alldata = []\n",
    "\n",
    "    for fol in folders:\n",
    "        print(fol, file = sys.stderr)\n",
    "        temp = u''\n",
    "        output = fol.replace('/', '-') + '.txt'\n",
    "\n",
    "        # Is there a better pattern to use?\n",
    "        txt_files = glob.glob('/'.join([dirname, fol, '*.txt']))\n",
    "\n",
    "        for txtfi in txt_files:\n",
    "            with open(txtfi, 'r', encoding='utf-8') as t:\n",
    "                control_chars = [chr(0x85)]\n",
    "                t_clean = t.read()\n",
    "\n",
    "                for c in control_chars:\n",
    "                    t_clean = t_clean.replace(c, ' ')\n",
    "\n",
    "            id_, stars_ = os.path.basename(txtfi).replace(\".txt\", \"\").split(\"_\")\n",
    "#             print(id_)\n",
    "            \n",
    "            dset, judgement = fol.split(\"/\")\n",
    "            alldata.append( \n",
    "                (dset, judgement, id_, stars_, normalize_text(t_clean) )\n",
    "                )\n",
    "            \n",
    "    return alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_reviews_file = \"../data/all_reviews.tab\"\n",
    "\n",
    "if not os.path.isfile(all_reviews_file):\n",
    "    \"if no summary file found, collect reviews from separate files:\"\n",
    "    alldata = collect_reviews(datadirname = \"../data/\")\n",
    "    alldatadf = pd.DataFrame(alldata,\n",
    "                 columns = (\"dataset\", \"judgement\", \"internal_id\", \"stars\", \"review\" )\n",
    "                )\n",
    "    alldatadf.index.name = \"id\"\n",
    "    alldatadf.to_csv(all_reviews_file, sep=\"\\t\")\n",
    "else:\n",
    "    \"read summary file\"\n",
    "    alldatadf = pd.read_table(all_reviews_file, index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !rm ../data/all_reviews.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_OK, now we are ready to play with our table!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>judgement</th>\n",
       "      <th>internal_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>bromwell high is a cartoon comedy .  it ran at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>pos</td>\n",
       "      <td>10000</td>\n",
       "      <td>8</td>\n",
       "      <td>homelessness  ( or houselessness as george car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>pos</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>brilliant over-acting by lesley ann warren .  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>pos</td>\n",
       "      <td>10002</td>\n",
       "      <td>7</td>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>pos</td>\n",
       "      <td>10003</td>\n",
       "      <td>8</td>\n",
       "      <td>this is not the typical mel brooks film .  it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset judgement  internal_id  stars  \\\n",
       "id                                         \n",
       "0    train       pos            0      9   \n",
       "1    train       pos        10000      8   \n",
       "2    train       pos        10001     10   \n",
       "3    train       pos        10002      7   \n",
       "4    train       pos        10003      8   \n",
       "\n",
       "                                               review  \n",
       "id                                                     \n",
       "0   bromwell high is a cartoon comedy .  it ran at...  \n",
       "1   homelessness  ( or houselessness as george car...  \n",
       "2   brilliant over-acting by lesley ann warren .  ...  \n",
       "3   this is easily the most underrated film inn th...  \n",
       "4   this is not the typical mel brooks film .  it ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore pandas data classes:\n",
    "    pd.DataFrame\n",
    "    pd.DataSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`DataFrame`** object `df` has 2 dimensions:\n",
    "\n",
    "+    rows indexed by `df.index`\n",
    "+   columns indexed by `df.columns`\n",
    "\n",
    "both belong to on of special classes `Index`, `Int64Index`, or `MultiIndex`\n",
    "\n",
    "index classes have properties `name` and `names` (which is useful for `MultiIndex`)\n",
    "\n",
    "sometimes it is useful to obtain index values as a list (`.tolist()`) or matrix (`.get_values()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'judgement', 'internal_id', 'stars', 'review'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList(['id'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.index.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column (or row) of `pd.DataFrame` can be extracted as an object of `pd.Series` class\n",
    "\n",
    "Usually you will need to extract a column, unless your whole DataFrame columns are of the same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "2     brilliant over-acting by lesley ann warren .  ...\n",
       "31    when i saw this movie i was stunned by what a ...\n",
       "32    why do people bitch about this movie and not a...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"two equivalent subsetting operations: DataFrame -> Series\"\n",
    "review = alldatadf[\"review\"]\n",
    "review = alldatadf.loc[:,\"review\"]\n",
    "\n",
    "\"\"\"a shorter Series: \n",
    "\"\"\"\n",
    "review = alldatadf.loc[alldatadf[\"stars\"]==10, \"review\"][:3]\n",
    "3review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing index\n",
    "\n",
    "You can pop-up index to a new column by calling\n",
    "\n",
    "    df.reset_index()\n",
    "    \n",
    "Or other way around, move regular columns to the index:\n",
    "\n",
    "    df.set_index(\"col_name\")\n",
    "    \n",
    "    df.set_index([\"col_name\"])\n",
    "    \n",
    "    df.set_index([\"col1\", \"col2\", \"col3\"])  # creates hierarchical MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>review_len</th>\n",
       "      <th>review_log_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>judgement</th>\n",
       "      <th>internal_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">neg</th>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>once again mr .  costner has dragged out a mov...</td>\n",
       "      <td>934</td>\n",
       "      <td>2.970347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>this is a pale imitation of 'officer and a gen...</td>\n",
       "      <td>755</td>\n",
       "      <td>2.877947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>it seems ever since 1982 ,  about every two or...</td>\n",
       "      <td>1493</td>\n",
       "      <td>3.174060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               stars  \\\n",
       "dataset judgement internal_id          \n",
       "test    neg       0                2   \n",
       "                  1                3   \n",
       "                  2                3   \n",
       "\n",
       "                                                                          review  \\\n",
       "dataset judgement internal_id                                                      \n",
       "test    neg       0            once again mr .  costner has dragged out a mov...   \n",
       "                  1            this is a pale imitation of 'officer and a gen...   \n",
       "                  2            it seems ever since 1982 ,  about every two or...   \n",
       "\n",
       "                               review_len  review_log_len  \n",
       "dataset judgement internal_id                              \n",
       "test    neg       0                   934        2.970347  \n",
       "                  1                   755        2.877947  \n",
       "                  2                  1493        3.174060  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"create multi-index reflecting initial folder structure\"\n",
    "alldatadf.set_index([\"dataset\",\"judgement\",\"internal_id\"]).sort_index()[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting columns\n",
    "\n",
    "call\n",
    "\n",
    "    df[\"col\"]\n",
    "    df.loc[:, \"col\"]\n",
    "    \n",
    "    df[[\"col\",\"col2\",\"col3\"]]\n",
    "    \n",
    "    df.iloc[:, :3]  # first three columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting rows\n",
    "\n",
    "might be confusing for DataFrame\n",
    "\n",
    "There are N ways to do it.\n",
    "\n",
    "First, using `df[]` is very ambigous.\n",
    "When used **with ranges**, such as `df[:4]`, `df[-5:]` it will subset first 4 or last 5 rows respectively. _Otherwise (with integers or strings) it will look for a column, not row!_, i.e. `df[4]` will look for column named `4`.\n",
    "\n",
    "If you need to get a row **by name**: use\n",
    "\n",
    "    df.loc[\"rowname\"]\n",
    "\n",
    "If you need to get a bunch of rows **by boolean mask**: use \n",
    "    \n",
    "    df.loc[mask]\n",
    "\n",
    "If you need to get a row **by ordinal number**: use \n",
    "\n",
    "    df.iloc[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars                                                             9\n",
       "review            bromwell high is a cartoon comedy .  it ran at...\n",
       "review_len                                                      886\n",
       "review_log_len                                              2.94743\n",
       "Name: (train, pos, 0), dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.set_index([\"dataset\",\"judgement\",\"internal_id\"]).loc[(\"train\", \"pos\", 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore pandas functionality:\n",
    "\n",
    "### `pd.Series` only\n",
    "    .map\n",
    "    .sort_values()\n",
    "    .value_counts() # for categorical data\n",
    "    \n",
    "### `pd.DataFrame` only\n",
    "\n",
    "    .T    #  transpose\n",
    "    .apply()     # one operation to whole row(axis=1)  or column(axis=0)\n",
    "    .applymap()  # an operation to each cell\n",
    "    .groupby().agg()   # ... key(s)\n",
    "    .corr() # useful for all-numeric data frames\n",
    "\n",
    "## Generic\n",
    "\n",
    "these methods accept `axis=` argument for DataFrame\n",
    "    \n",
    "    .all()\n",
    "    .any()\n",
    "    \n",
    "    .hist()\n",
    "    .median()\n",
    "    .mean()  # <- do not run them on the full alldatadf data frame, as it contains text\n",
    "    .var()\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     50000\n",
       "1     10122\n",
       "10     9731\n",
       "8      5859\n",
       "4      5331\n",
       "3      4961\n",
       "7      4803\n",
       "9      4607\n",
       "2      4586\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[\"stars\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>judgement</th>\n",
       "      <th>internal_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>review_len</th>\n",
       "      <th>review_log_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'float'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'float'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>&lt;class 'int'&gt;</td>\n",
       "      <td>&lt;class 'float'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset      judgement    internal_id          stars         review  \\\n",
       "id                                                                              \n",
       "0   <class 'str'>  <class 'str'>  <class 'int'>  <class 'int'>  <class 'str'>   \n",
       "1   <class 'str'>  <class 'str'>  <class 'int'>  <class 'int'>  <class 'str'>   \n",
       "2   <class 'str'>  <class 'str'>  <class 'int'>  <class 'int'>  <class 'str'>   \n",
       "\n",
       "       review_len   review_log_len  \n",
       "id                                  \n",
       "0   <class 'int'>  <class 'float'>  \n",
       "1   <class 'int'>  <class 'float'>  \n",
       "2   <class 'int'>  <class 'float'>  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[:3].applymap(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset            object\n",
       "judgement          object\n",
       "internal_id         int64\n",
       "stars               int64\n",
       "review             object\n",
       "review_len          int64\n",
       "review_log_len    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"a more conventional way\"\n",
    "alldatadf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_len        1363.007750\n",
       "review_log_len       3.038691\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"take mean of two last columns \n",
    "(it will freak out on text data if you ask it for the whole table)\"\"\"\n",
    "alldatadf.iloc[:,-2:].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judgement</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">neg</th>\n",
       "      <th>test</th>\n",
       "      <td>1328.19096</td>\n",
       "      <td>962.690501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1345.98112</td>\n",
       "      <td>985.517630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pos</th>\n",
       "      <th>test</th>\n",
       "      <td>1344.85208</td>\n",
       "      <td>1046.257139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1391.15688</td>\n",
       "      <td>1078.574059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsup</th>\n",
       "      <th>train</th>\n",
       "      <td>1373.47024</td>\n",
       "      <td>1035.349699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean          std\n",
       "judgement dataset                         \n",
       "neg       test     1328.19096   962.690501\n",
       "          train    1345.98112   985.517630\n",
       "pos       test     1344.85208  1046.257139\n",
       "          train    1391.15688  1078.574059\n",
       "unsup     train    1373.47024  1035.349699"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[\"review_len\"] = alldatadf[\"review\"].map(len)\n",
    "alldatadf[\"review_log_len\"] = alldatadf[\"review_len\"].map(np.log10)\n",
    "alldatadf.groupby([\"judgement\", \"dataset\"]).agg([np.mean, np.std])[\"review_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_len    1363.00775\n",
       "stars            2.74767\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[[\"review_len\",\"stars\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAK5CAYAAAC2WvlHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0bFV55/3vD1RUQAyQPjtcT7yFNs1FozQ9sOWIiYKa\n6PBNh8A7MNptYo8YtTsXlcSE2FFjXuOQVlECjaRJXhsTk+7gK4SMJhyUcBHlagQR9KAe5NAIijfw\nCM/7R60jZVFn79p7r1W7aq/vZ4wap6rWqjln7bNmPTVrrjWfVBWSpP7ZZa0bIElaGwYASeopA4Ak\n9ZQBQJJ6ygAgST1lAJCknjIATCDJO5K8fq3b0aUkH03ywrVuh2bTeuoDSS5IcvKE+67rfhGvA1hc\nkn2Ba4GnVNUDa9yWh5p2fHGV5ZwKPLmqXjH03LOBD1bVs1bZTK0z67EPLKO+dd0vHAEs7ZXABWt9\n4Dc6i9ZVdTWwZ5JndlWH5tYrmZM+kGTXVitb5/3CALC044FLdzxIckySryT5zSTbkmxN8sqh7Y9J\n8qdJbk/ytSQfSLLb0PY3JrkjyVeT/IckDyV50lKNSHIpEOCGJPcl+XfN8y9Jcm2Se5NcluTQode8\nqannviQ3JXleM5z9XeCEJN9Kcu1QNZcCL175n0rr1Mz2gaG2vDHJ14APJXliko8luSvJ15v7+w+V\nc0mSf9/c/5Ukn0zyriT3JLktyXEjVa/bfmEAWNqhwOdHnlsA9gT2A14NnJ5kr2bbnwBPAQ5r/t0f\n+AOA5sD6T8CxzbZNTPitvqqO2dGeqnpCVf11kmcAZwO/CuwN/BlwfpJHJ3ka8FrgZ6rqCcALgS1V\ndRHwDuAjVbVnVT1jqJqbgMMnaY96ZWb7wFBbnggcBPwag8+1DwEHNs99F3j/IkUfyeDY3wd4F4M+\nNWzd9gsDwNKeCHxr5LnvA39UVQ9W1YXAt4Gfarb9KvCfq+qbVfUd4J3Aic22fwecU1U3V9X9wB+u\noD0Zuv+rwBlV9eka+AvgAeAo4EHgMcC/SvKoqvpyVX1pibK/1bxfadgs9wEYHOunVtX2qnqgqu6p\nqv/Z3P8O8MfAcxcp7/aq+lANJkT/O7CQ5F8MbV+3/eJRa92AOXAvg286w75eVQ8NPf4usEeSHwce\nD3wm+eExugsPH7D7AVcPve4rPPJgXo6DgVckeV3zOMCjgf2q6pNJ/hODDvb0JBcBv1lVdy5S3p7A\nN1bRHq1Ps9wHAP5PVW3f8SDJ44DTGIx6n9iUv0eS1PizXn7YJ6rqexk0fA/grubpddsvHAEs7Qbg\naRPuezeDjvDTVbV3c3tiVe0YGn8NOGBo/4NY3cTuV4C3D9X1Y1W1R1V9BKCqzquqf8sgUMBgaM4i\ndf5L4PpVtEfr0yz3Aca8/reApwLPrqon8vC3/5UGmnXbLwwAS7uAwe+US2q+XZwFnNZ8EyLJ/kle\n0OzyV8CrkhyS5PHAW4Zf30xILfYzzZ3A8GTZWcB/THJk8/rdk7yo+fdpzaTvYxgM178H7PjGtg3Y\nmKGvaI1jgAsnea/qlVnuA+PsyeB4vy/J3qzsZ6Zh67ZfGACWdi5w/PBZDGMMfwN5M3ArcGWSbwD/\nQPPtqar+HngvcAlwC3BF85odp9cdCFy2SD1/CJzbnK3wi1X1GQa/t74/yT1Nmb/S7Lsbg99e/w9w\nB/DjwCnNtr9m8G3o60k+DT883/lbVfXpRepXP81sH9jJPqcx+BnqbuByBgFsZ21d9L2s936x5IVg\nSc4GXgJsq6rDxmzfB/hL4CeAXYF3V9Wft9/UtZPkbcBdVfXelss9BLgR2K2qHkry98Abqmr0jIvO\nJfko8N+aDir9iD70gXHWe7+YJAA8h8EM/7k7CQCnAo+tqlMyuGLw88CGqvpBFw2ed0lexuAbye7A\nnwM/qKr/a00bJU2RfWB2LPkTUFVdxuAsgJ25k4fPENiTwdkBfvjv3GsYnF3wBWA78Otr2xxp6uwD\nM6KN00DPAi5OcgeDU6dOaKHMdauqjl/rNkhryT4wO9qYBD4FuL6q9gOeweCKwD1aKFeS1KE2RgBH\nA28HqKrbmlO4DgEeMWuexKVH1YmqWu3FRFNnf1BXJu0Pk44Aws4vorgJ+FmAJBsYnO6106Vaq2rq\nt1NPPdV613G986xP/0/WO53bciw5AkjyYQYXgeyT5MvAqQzWmKmqOpPBOhvnJLmeQZB4Y1Xds8x+\nIEmasiUDQFWdtMT2u4Gfb61FkqSp6MWVwJs2bbLedVyvlqdvx0ff6l2OqaaE3PlifNLKJaHmdBLY\n/qC2Lac/9GIEIGn9WVjYSJJl3xYWNq5102eGIwDNPUcA/TRYzHYlf78s+2yZeeIIQJK0JAOAJPWU\nAUCSesoAIEk9ZQCQpJ5aMgAkOTvJtiQ3LLLPpiTXJvlskkvabaIkqQttZATbi0HezRdU1dYk+zbL\nQ4wry9Pe1DpPA+0nTwMdr9XTQGvpjGAnAX9TVVub/cd++EuSZksbcwBPA/ZOckmSq5Oc3EKZkqSO\ntZEQ5lHAM4FjGSR5viLJFVV1awtlS5I60kYA+Cpwd1XdD9yf5BPA4cDYALBp0yY2btzIxo0b2bRp\n01ysmKfZsnnzZjZv3syWLVvYsmXLWjdnVewPWq3V9IeJ1gJKshH4WFUdOmbbIcD7gOOA3YCrgBOq\n6nNj9nXSS61zErifnAQebzn9YdUZwarq5iQXATcADwJnjvvwlyTNFlcD1dxzBNBPjgDGczVQSdKS\nDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkA5tzCwkaSLPu2sLBxrZsuaY21khGs\n2e/ZSbYneXl7zdNStm27ncHVkMu7DV4nqc8mGQGcA7xwsR2S7AK8E7iojUZJkrrXRkYwgNcBHwXu\naqNRkqTurXoOIMl+wMuq6oPA3C3IJUl91cYk8GnAm4YeGwQkaQ60kRHsWcB5GazNui9wfJLtVXX+\nuJ3NgKTVMiOY9LA1zQg2st85zX5/u5Ptrn/eMtdENx9AX3nsjzfVjGAju6/fv6okrTNmBJtzfgty\nBNBXHvvjmRFMkrQkA4Ak9ZQBQJJ6ygAgST1lAJCknjIASFJPGQAkqacMAJLUUwYASeqpVWcES3JS\nkuub22VJFl0vSJI0G9rICPZF4LlVdTjwNuCsNhomSerWkovBVdVlSQ5eZPuVQw+vBPZvo2GSpG61\nPQfwauDClsuUJHWgjYQwACR5HvAq4DltlSlJ6k4rASDJYcCZwHFVtWgCeTMgabXMCCY9bE0zgiU5\nCLgYOHlkPmBcOa5/voiFhY1s23b7Cl7Z7zXRzQfQT+YDGG85/WHJADCcEQzYxkhGsCRnAS8HbmeQ\nEH57VR25k7I84BexsgPaTmAA6CcDwHitBoA2ecAvzgCwMgaAfjIAjGdGMEnSkgwAktRTBgBJ6ikD\ngCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSpp1adEazZ571JvpDkuiRHtNtESVIXVp0RLMnxwJOr\n6qnAa4AzWmqbJKlDSwaAqroMWGyJ55cC5zb7XgXslWRDO82TJHWljTmA/YGvDD3eimkhJWnmOQks\nqWd2I8mybgsLG9e60Z1oIyPYVuDAoccHNM+NZQYkrZYZwbQ6D7DcZaS3bZvd1cbXOiPYi4DXVtWL\nkxwFnFZVR+2kHNc/X4T5AFbGfAD9tJp8ACvpZ/Pyf7Wc/rDkCGA4I1iSLzOSEayqLkjyoiS3At9h\nkBhekjTjzAg2QxwBrIwjgH5yBDCeGcEkSUsyAEhSTxkAJKmnDACS1FMGAEnqKQOAJPWUAUCSesoA\nIEk9ZQDoLRfEkvpuogCQ5LgkNye5JcmbxmzfJ8mFTUawG5O8svWWqmU7FsSa/LZt2+1r01RJnVhy\nKYgkuwC3AM8H7gCuBn65qm4e2udU4LFVdUqSfYHPAxuq6gcjZXnp+yKmvRTEerkc3qUg+smlIMZr\neymII4EvVNXtVbUdOI9BFrBhdwJ7Nvf3BL4++uEvSZotk+QDGM349VUGQWHYWcDFSe4A9gBOaKd5\nkqSutDUJfApwfVXtBzwDOD3JHi2VLUnqwCQjgK3AQUOPx2X8Ohp4O0BV3ZbkS8AhwKdHCzMDklbL\njGDSwzrNCJZkVwaTus8HvgZ8Cjixqm4a2ufdwH1V9dYkGxh88B9eVfeMlOWk1yKcBF4ZJ4H7yUng\n8VrNCFZVDyb5DeAfGPxkdHZV3ZTkNTRZwYA/Bs5Jcj2Dv+4bRz/8JUmzxYxgM8QRwMo4AugnRwDj\nmRFMkrQkA4Ak9ZQBQJJ6ygAgST1lAJCknjIASFJPGQAkqacMAJLW3MLCxmUnKNLqeSHYDPFCsJXx\nQrD557HfntYvBFsqI1izz6Yk1yb5bJJLltNgSdL0tZURbC/gcuAFVbU1yb5VdfeYsvzGswi/Ba2M\nI4D557HfnrXICHYS8DdVtRVg3Ie/JGm2TBIAxmUE239kn6cBeye5JMnVSU5uq4GSpG5MkhBm0nKe\nCRwL7A5ckeSKqrq1pfIlSS1rKyPYV4G7q+p+4P4knwAOBx4RAMyApNUyI5j0sFnICHYI8D7gOGA3\n4CrghKr63EhZTnotwomwlXESeP557Ldn6hnBqurmJBcBNwAPAmeOfvhLkmaLF4LNEL8FrYwjgPk3\n+8f+Y4EHll3Thg0Hc+edW5b9utVodQQgSXqAlQSbbdtm+3uJawFJUk8ZACSppwwAktRTBgBJ6ikD\ngCT1lAFAknrKACBJPWUAkKSeai0jWLPfs5NsT/Ly9pooSerCkgGgyQj2fuCFwE8DJzaLv43b753A\nRW03UpLUvrYyggG8DvgocFeL7ZMkdaSVjGBJ9gNeVlUfZLDSkiRpxrU1CXwaMDw3YBBYl3YjybJv\nCwsb17rhksZoKyPYs4DzMljTdV/g+CTbq+r80cLMgDTPZmNFRDOCSQ9b84xgI/ufA3ysqv52zDbX\nP1/E7K+JvvK6uvx/Nx/A/PPYb8/UM4KNvmTZLZYkTZ0ZwWaI34JWxhHA/PPYb89y+oNXAktSTxkA\nJKmnDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAHRgYWHjihZNk6RpaiUjWJKTklzf3C5L\ncmj7TZ0f27bdzuCqweXeJGl62soI9kXguVV1OPA24Ky2GypJalcrGcGq6sqq+mbz8EpGEsZIkmZP\nKxnBRrwauHA1jZIkda/VSeAkzwNexY9mB5PUIys5CWL9Wn4WvWlm0GsrIxhJDgPOBI6rqnt3VpgZ\nkLRaZgSbbQ+fBLEc6zUILD+L3nIz6K15RrAkBwEXAydX1ZWLlNWL9c9XtrY5THud8vWyJrr5AGbL\n9Nb2n49jfyV1rea4WIuMYL8P7A18oMkLvL2qjlzxO5Akdc6MYB1wBPDI1zkCeKT12h8cAay+rmmN\nALwSWJJ6ygCgKZjtMyGkvprkLCBplbo/E0LS8jkCkKSeMgBIUk8ZABbhss6S1jNPA13EdE/nXOnr\n1m9dkx4rngY6WzwNdPV1eRqoJKlTBgBJ6qlWMoI1+7w3yReSXJfkiHabKUlqWysZwZIcDzy5qp4K\nvAY4o4O2rtjmzZvXqmbr1cyZtD+0fxLEZPW2r2/1Tq6VjGDN43MBquoqYK8kG1pt6SoYANZ7vVqO\nSftD+7mtJ6u3ffNW7/SunG8rI9joPlvH7CNJWtKOK+cnvw2C9fKt2STwscf+3IqGl+95z3tXVJ9Z\nirQeLCzst6J+s88++//w/lvf+laPfwGTJYQ5CvjDqjquefxmBnkA/mRonzOAS6rqI83jm4Fjqmrb\nSFnr76RnzYR5vQ5grdug9am1hDDA1cBTkhzMICPYLwMnjuxzPvBa4CNNwPjG6If/chol9YH9QWut\nlYxgVXVBkhcluRX4DoPE8JKkGTbVpSAkSbPDK4ElqacMAJLUU+s2I1hzIdqOaxG2jpuUnkIb9q6q\ne6ZUl+9XY83C36pvx8a8vN9pLwfd+R+lWYfoDGAvBhekARwAfAP49aq6pqN631JVb2vuPx34X8Cj\nGawHe0JzhXQX9fp+p/B+u9B1f/DYAHy/i6uqTm7AW4buPx24BfgSsAX41x3We9248oGjgOs7rPea\nofsfB45v7h8JXO77ne/320K7p94fPDZ8v0vdupwDePnQ/XcBb6iqnwR+CXhPh/XuXmMiblVdCeze\nYb3D9q+qC5t6PwU8rsO6fL9M/f2uxFr0h1n4W/Xt2Jir9zutOYAf+aMk6fKPcmGSjzNYnG7H+kQH\nAq8A/r7Dep+U5HwGw74Dkjy+qr7bbHt0h/X6fqfzfts0rf7gseH7XVRncwBJvgF8gsEf5d8AB+34\noyT5bFX9q04q5ofLU7+UoYkR4PyquqDDOo8ZeeozVfXtZoLmF6vq9A7r9v12/H5Xa636g8eG73fR\n13cYANbsjyLNGvuDZlFncwBVdenI7dvN89vW6mBP8mvWa71rYdb6Q9/+j6x3vDW5EGwNO+paLb5l\nveu73lVZo/7Qt/8j6x1jrS4E6/SPkkHKyv2Bq3Z802qsLGvC7Nd7NHBvVX2u+anhWcB1VfVn67He\nMe04t6peMe16W9RZf7Av2BcW3b+rOYBFK01eVVXndFT26xksTX0TcASD0+3+rtl2TVU9c53V+w7g\nWAajuc3Acxmci/xzDCaD/nSd1Xv+6FPA84B/BKiqX+ii3i511R/sC/aFJQtZ6UUIq7kBX+6w7BuB\nPZr7G4FPMzgAAa5dh/X+M7Ar8HjgPuAJzfOPo9uLX9aq3muAvwQ2Acc0/36tuX9MV/V2eeuqP9gX\n7AtL3Tr7CSjJDTvbBHSZMH6XeniCbUuSTcBHm4Q2Xf70tFb1fr+qHgS+m+S2qrqvacP3kjy0Dut9\nFvAG4PeA36mq65J8r6ou7bDOVVuj/mBfwL6wmC7nADYALwTuHXk+wOUd1rstyRFVdR1ADU61ewnw\nIeDQdVjv94cuPPmZHU8m2YtBxuh1VW9VPQS8J8lfN/9uYz4WNVyL/mBfwL6wmC6vAzgbOKeqLhuz\n7cNVdVJH9R4A/KCq7hyz7eiq+qd1Vu9uVfXAmOf3BX6iqm5cT/WOqe/FwNFV9bvTqG+l1qI/2Bd+\n+Lx9YWev6SoASJJmmwlhJKmnDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmn\nDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmnDACS1FMGAEnqKQOAJPWUAUCS\nesoAIEk9ZQCQpJ4yAEhSTxkAJKmnDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkA\nJKmnDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmnDACS1FMGAEnqKQOAJPWU\nAWBCSd6R5PVr3Y4uJPkXST6X5NFr3RbNpvVw/Cc5MMl9STLBvr3oEwaACSTZFzgZ+LM1bMOvJPlk\nS2V9KcmxOx5X1V3APwKvaaN8rS/r5fivqq9U1ROqqibYtxd9wgAwmVcCF1TVA2vYhgBLHrir8GHW\n+cGuFXslc3D8J2n782zd9wkDwGSOBy7d8SDJMUm+kuSUJP8nyReTnDS0/QlJzk1yV/Nt+/eGtj05\nyeYk32i2/4+lKk9yCPBB4N8k+VaSe5rnH5PkT5PcnuRrST6QZLdm2z5JPpbk3iRfT3Jp8/y5wEHA\nx5rh8G831VwFPCnJgav+a2m9mdXj/5zmmP94km8Bm5K8KMk1Sb7Z9ItTh8o5OMlDOwJFkkuS/Jck\nlzV94e+T7D1U9brvEwaAyRwKfH7kuQVgb2A/Bt+Qzkzy1Gbb+4E9gY3AJuAVSV7VbPsj4KKqeiJw\nAPC+pSqvqpuB/whcUVV7VtWOg/RPgKcAhzX/7g/8QbPtt4CvAPsA/wL43aasVwBfBl7SDIf/tHn+\nQeBW4PAl/xrqm1k9/gFOBP6oqvYELgO+DZxcVXsBLwb+Y5JfGC5upPgTgV8BfhzYDfjtH+7Ygz5h\nAJjME4FvjTxXwO9X1faq+gTwceCXmm8XJwBvrqrvVtXtwLsZ/IYKsB04OMn+VfX9qrp8Fe36VeA/\nV9U3q+o7wDsZHNA76vkJ4Cer6sGq+qeR146bCPtW816lYbN6/AP8XVVdCdCU94mq+ufm8WeB84Bj\nFnn9OVV1W/Pz1l8BR4xsX9d9wgAwmXsZfKP5keeq6v6hx7cz+Da0L/BoBt+yh7ft39x/I4O/+6eS\n3Dj0zWhZkvw48HjgM0nuaYbFFzL4xg/wLuA24B+S3JrkTRMUuyfwjZW0R+vazB3/Q74y/CDJkUn+\nsfl56RsMfsPfd5HX3zl0/7vAHiPb13WfMABM5gbgaSPP/ViSxw09Pgi4A7ib5lvO0LaDga0AVbWt\nqn6tqvZnMKz9QJInTdCG0aHr3QwO2J+uqr2b2xOboS9V9e2q+u2qejLwC8BvJnneTsoiya4Mfka6\nfoK2qF9m8fjf2fMfBv4XsH/zM9OfMX60u6Q+9AkDwGQuYPBb5rAAb03y6CT/lsHvjX9VVQ8BHwHe\nnmSPJAcD/xn4C4Akv5hkx7ehbwAPNbcdk1J/wHjbgAN2nJfcnMp2FnBaMxogyf5JXtDcf3GSJzev\n/RbwA+DBobJGO92RwJeq6itIP2rmjv9F7MFgdLI9yZHASSPblxMM1n2fMABM5lzg+B1n2DS+xmBo\nfAeDg/s1VfWFZtvrGXw7/yLwCeAvq+qcZtuzgauS3Mfgm8rrq2pLs+1ABhNZ4/wj8M/AnUnuap57\nM4NJqiub4e4/8PA3tacC/7s5O+KfgNOb32oB/hj4/eano99snvu/gTMm/YOoV2b1+B/n14E/SvJN\n4C0MgtGw2sn9cdZ9n8hS10QkORt4CbCtqg4bs30f4C8ZTDjuCry7qv68/aaurSRvA+6qqvcmOQb4\ni6o6qMXy9wc+UlXPaavMZdT948Bm4BlV9f1p16/Zt56P/3H60icmCQDPYXBq1bk7CQCnAo+tqlMy\nuGLw88CGqvpBFw2eBV10AGleePyvH0v+BFRVlzEY6u3MnTx8hsCewNfX84e/JK0XS44AYHAFHfCx\nnYwAdgEuBn6KwQTMCVV1YdsNlSS1q41J4FOA66tqP+AZwOlJRs+llSTNmEe1UMbRwNsBquq2JF8C\nDgE+Pbpjki4XM1OPVdWKzvVeS/YHdWXS/jDpCCDs/PzZm4CfBUiygcFpiF9cpGGd3k499VTr6Fkd\n82w9/P2tY7bqWI4lRwBJPszgIpB9knwZOBV4zODYrTMZnFN+TpLrGQSJN1bVPcvsB5KkKVsyAFTV\n6JV0o9vvBn6+tRZJkqZi3V0JvGnTJuvoWR3aufXyf2wd3ZjoNNDWKktqmvWpH5JQczoJbH9Q25bT\nH9bdCECSNBkDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSpp5YMAEnOTrItyQ2L7LMpybVJPpvk\nknabKEnqQhsZwfYCLgdeUFVbk+zbLA8xriwvfFHrvBBMelirF4LV0hnBTgL+pqq2NvuP/fCXJM2W\nNuYAngbsneSSJFcnObmFMiVJHWsjIcyjgGcCxwK7A1ckuaKqbm2hbElSR9oIAF8F7q6q+4H7k3wC\nOBwYGwA2bdrExo0b2bhxI5s2bZq51fE0+zZv3szmzZvZsmULW7ZsWevmrEqf+8PCwka2bbt9on03\nbDiYO+/c0m2D5tRq+sOkSeE3MkgKf+iYbYcA7wOOA3YDrmKQGP5zY/Z10kutcxJ4PiUBJn3/WXa2\nq75aTn9YdUawqro5yUXADcCDwJnjPvwlSbPFfACae44A5pMjgG6YD2AGLSxsJMnEt4WFjWvdZEnr\nnCOAKVnetx3wG8/kHAHMJ0cA3XAEIElakgFAknrKACBJPWUAkKSeMgBIUk8ZACSppwwAktRTrWQE\na/Z7dpLtSV7eXvMkSV2ZZARwDvDCxXZIsgvwTuCiNholSepeGxnBAF4HfBS4q41GSZK6t+o5gCT7\nAS+rqg8Cc3c5viT1VRuTwKcBbxp6bBCQpDnQRkawZwHnZbCy077A8Um2V9X543bucwYktcOMYNLD\n1jQj2Mh+5zT7/e1Otvd29UNXA+2Oq4HOJ1cD7cZUM4KN7O7/kCTNCfMBTIkjgO44AphPjgC6YT4A\nSdKSDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmnVp0RLMlJSa5vbpclWXS9\nIEnSbGgjI9gXgedW1eHA24Cz2miYJKlbSy4GV1WXJTl4ke1XDj28Eti/jYZJkrrV9hzAq4ELWy5T\nktSBNhLCAJDkecCrgOe0VaYkqTutBIAkhwFnAsdV1aIJ5M2ApNUyI5j0sDXNCJbkIOBi4OSR+YBx\n5fR2/XPzAXTHfADzyXwA3Zh2RrDfB/YGPtDkBd5eVUeutPGSpOkwI9iULH8E8FjggYn23LDhYO68\nc8sKWrU+OAKYT44AurGc/mAAmJKV/ARk55iMAWA+GQC6YUpISdKSDACS1FMGAEnqKQOAJPWUAUDS\nHNiNJBPfFhY2rnWD54JnAU2JZwF1x7OA5tNyzwLyQsrJeBaQJGlJBgBJ6qlVZwRr9nlvki8kuS7J\nEe02UZLUhVVnBEtyPPDkqnoq8BrgjJbaJknq0JIBoKouAxZb4vmlwLnNvlcBeyXZ0E7zJEldaWMO\nYH/gK0OPt2JaSEmaeU4CS1JPtZERbCtw4NDjA5rnxjIDklbLjGDSw9Y6I9iLgNdW1YuTHAWcVlVH\n7aSc3l744oVg3fFCsPnkhWDdmGpGsKq6IMmLktwKfIdBYnhJ0oxzKYgpcQTQHUcA88kRQDdcCkKS\ntCQDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSppwwAktRTBgBJ6qmJAkCS45LcnOSWJG8as32f\nJBc2GcFuTPLK1lsqSWrVkktBJNkFuAV4PnAHcDXwy1V189A+pwKPrapTkuwLfB7YUFU/GCmrt5e+\nuxREd1wKYj65FEQ32l4K4kjgC1V1e1VtB85jkAVs2J3Ans39PYGvj374S5JmyyT5AEYzfn2VQVAY\ndhZwcZIBqtYMAAAbCUlEQVQ7gD2AE9ppniSpK21NAp8CXF9V+wHPAE5PskdLZUuSOjDJCGArcNDQ\n43EZv44G3g5QVbcl+RJwCPDp0cLMgKTVMiOY9LBOM4Il2ZXBpO7zga8BnwJOrKqbhvZ5N3BfVb01\nyQYGH/yHV9U9I2X1dtLLSeDuOAk8n5wE7karGcGq6sEkvwH8A4OfjM6uqpuSvIYmKxjwx8A5Sa5n\n8D/1xtEPf0nSbDEj2JQ4AuiOI4D55AigG2YEkyQtyQAgST1lAJCknjIASFJPGQAkqacMAJLUUwYA\nSeopA8C6sBtJJr4tLGxc6wZLmgEGgHXhAQYXyUx227bt9jVqpzQtk38p6vMXolYygjX7bEpybZLP\nJrmk3WZK0nJM/qWoz1+I2soIthdwOfCCqtqaZN+quntMWb299L3rpSD6fJm8S0HMp66XgujrUipr\nkRHsJOBvqmorwLgPf0nSbJkkAIzLCLb/yD5PA/ZOckmSq5Oc3FYDJUndmCQhzKTlPBM4FtgduCLJ\nFVV1a0vlS5Ja1lZGsK8Cd1fV/cD9ST4BHA48IgCYAUmrZUYw6WGzkBHsEOB9wHHAbsBVwAlV9bmR\nsno76eUkcHecBJ5PTgJ3Y+oZwarq5iQXATcADwJnjn74S5JmixnBpsQRQHccAcwnRwDdMCOYJGlJ\nBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSppwwAktRTrWUEa/Z7dpLtSV7eXhMlSV1Y\nMgA0GcHeD7wQ+GngxGbxt3H7vRO4qO1GSpLa11ZGMIDXAR8F7mqxfZKkjrSSESzJfsDLquqDDFZh\nkiTNuLYmgU8DhucGDAKSNOPaygj2LOC8DNZ33Rc4Psn2qjp/tDAzIGm1zAgmPWzNM4KN7H8O8LGq\n+tsx23q7/rn5ALpjPoDZsLCwkW3bbl/mq8wH0LZW8wFU1YPAjoxg/wyctyMjWJJfG/eSZbV2ji0s\nbCTJRDdpvRt8+NcyblprZgRbhVnKaOQIwBHAWpu1Ua4jgKV5JbAk9ZQBQJJ6ygAgqed2m3gub2Fh\n41o3tlUGgF7q7wEvPdIDTDpxvfyznGbbJNcBaN3ZccAvbdu2uZtblTQhRwCS1FMGAEnqKQOAJPWU\nAUCSeqqVjGBJTkpyfXO7LMmh7TdVktSmtjKCfRF4blUdDrwNOKvthkqS2tVKRrCqurKqvtk8vJKR\nhDGSpNnTSkawEa8GLlxNoyRJ3Wv1QrAkzwNeBTynzXIlrY2VrfGvedFWRjCSHAacCRxXVffurDAz\nIGm1zAg2PQ+v8T8JrxpfC2ueESzJQcDFwMlVdeUiZfV4/XPXSu+K+QC605djvK/9YckRQFU9mGRH\nRrBdgLN3ZAQbbK4zgd8H9gY+0OQF3l5VR678LawNh7uS+sSMYEPmOaORIwBHAF1wBPDIfefh/8yM\nYJKkRRkAJKmnDACS1FMGAEnqKQOAJPWUAUCSesoAoCWYQF5arwwAWsKOBPJL37yITuvf5F+I5uFL\nUauLwUnS+rbjC9Fktm2b7esTW8kI1uzz3iRfSHJdkiPabaYkqW2tZARLcjzw5Kp6KvAa4IwO2jqR\nzZs3T6OWKdQxDZu7r2Eq/x/aGfvDcmzuvoYZ6w+tZARrHp8LUFVXAXsl2dBqSyfkAb8cm7uvYcYO\n+L6xPyzH5u5rmLH+0FZGsNF9to7ZZ00sLGyceMJGWu+W0x/sE+vfXJ0FdOONNy55wL71rW/9kccP\nJ7SY5CbNl0svvbTD/mCfWO8mSQhzFPCHVXVc8/jNDPIA/MnQPmcAl1TVR5rHNwPHVNW2kbI8otSJ\neV0Oeq3boPWptYQwwNXAU5IczCAj2C8DJ47scz7wWuAjTcD4xuiH/3IaJfWB/UFrrZWMYFV1QZIX\nJbkV+A6DxPCSpBk21YxgkqTZMVeTwJKk9hgAJKmn1sVaQM1FZzuuO9g6bgK65fr2rqp7OijX97Gy\n+jp5H/NovfztfR8rrm9576OqpnYD9m65vCOAK4GbgP/d3G5unntmS3W8Zej+04FbgC8BW4B/7ftY\nf+9jWrc2+8N6+dv7Pqb7Plo/qKf8R75uXFnAUcD1LdVxzdD9jwPHN/ePBC73fay/99HFrev+sF7+\n9r6P6b6PLucAXj50/13AG6rqJ4FfAt7TUh2712DtoR9RVVcCu7dUx7D9q+rCpo5PAY9rqVzfx8p0\n9T660HV/WC9/e9/HyqzofUxrDuBHGpekrT/yhUk+zmAhuh1rER0IvAL4+5bqeFKS84EAByR5fFV9\nt9n26Jbq8H1Mbhrvo2td9If18rf3fUxu1e+jywDQ+R+5ql7fLEX9UoYmWoDTq+qCNurgkSuf7gI/\nnNz5YBsV+D6WpfP30ZFO+8N6+dv7PpZl1e+jswvBkhwz8tRnqurbTeN+sapO76RiaQbZHzSLOpsD\nqKpLR27fbp7fNo2DPcmvWYd1zIq17A/r5W9vHe3XsSYXgk2po05joS3r6F8drZtCf1gvf3vraLmO\ntboSuLU/QJJDkjw/yR4jm26fszqOTvL05v4xSX4ryfOr6s/mqY4xde7IFDfXdXSslf5gX5itOsbU\nOXN9YU0Wg0vyqqo6p4VyXs9gGeqbGFx48Yaq+rtm2zVV9cw5qeMdwLEMAvJm4LkMzuv9OeD8qvrT\nOanj/NGngOcB/whQVb8wD3VMWxv9wb4wc3XMR19o44KE5d6AL7dUzo3AHs39jcCnGRyUANfOUR3/\nDOwKPB64D3hC8/zjaO+ikWnUcQ3wl8Am4Jjm368194+ZlzqmfWujP9gXZq6OuegLnZ0GmuSGnW0C\n2koYv0s9PJm2Jckm4KNN8pq2fmaaRh3fr6oHge8mua2q7mvq+16Sh+aojmcBbwB+D/idqrouyfeq\n6tKWyp9WHa2bQn+wL8xWHXPRF7q8DmAD8ELg3pHnA1zeUh3bkhxRVdcB1OC0upcAHwIOnaM6vj90\nXvjP7HgyyV60l5i18zqq6iHgPUn+uvl3Gy0fY9OooyNd9wf7wgzVMTd9oY2hyE6GJ2cDz9nJtg+3\nVMcBwMJOth09R3XstpPn9wUOnZc6xpT9YuAdXZQ9zTpaamen/cG+MFt1jCl7JvuCGcEkqadMCCNJ\nPWUAkKSeMgBIUk8ZACSppwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSppwwA\nktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSppwwAktRTBgBJ6ikDgCT1lAFAknrK\nACBJPWUAkKSeMgBIUk8ZACSppwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSp\npwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk8ZACSpp3odAJK8I8nr17odaynJKUnO\nnHDf30jyzq7bJGk6UlVr3YY1kWRf4FrgKVX1wFq3ZyWSXAL8RVV9aEr17QbcCjyjqu6eRp2SutPn\nEcArgQvm9cN/Ekl2bbO85m91AfCKNsuVtDb6HACOBy7d8SDJryT55PAOSR5K8qTm/jlJ3p/k/0ty\nX5Irkvzk0L7vSbItyTeTXJ/k6c3zlyT59zurp6njdUluS3JXkv9nksYneRvwb4H3N+1571B5v57k\nFuCW5rnTkny5advVSZ4zVM6pSf6iuX9w8/pXJLm9ac/vjlR9KfDiSdooabb1OQAcCnx+5LnR38NG\nH58AnAo8EbgNeDtAkhcAz2Hwc9JewC8BX1+k7tFyXwY8s7m9dDhg7LSAqrcAnwR+o6qeUFXDcxkv\nBZ4NPL15/CngMODHgA8Df53kMYu052jgqcDPAn+Q5KeGtt0EHL5U+yTNvj4HgCcC31pin4w8/p9V\n9Zmqegj4f4Ejmue3A3sCT0+Sqvp8VW1bRlveWVXfrKqvAqcBJy7jteO8oynvAYCq+nBVfaOqHqqq\n9wC7AT+1k9cW8IdV9f2qugG4nh/9wP8WsNcq2ydpBvQ5ANzL4EN7Oe4cuv9dYA+AqroEeD9wOrAt\nyRlJ9lhGuV8dun87sN8y27VYeST57SSfS3JvknuBJwD7LvL64eD1w/fZ2BP45irbJ2kG9DkA3AA8\nbejxd4DH73iQZGE5hVXV+6vqWQx+dvkp4HfGlQuMK/fAofsHAXdMWu1Szze/9/8O8ItV9WNV9WPA\nfTxydDOpf8lgVCBpzvU5AFwAbBp6fD3w00kOa053PJWdf8D+iCTPSnJkkkcB3wPuBx5qNl8HvDzJ\n45I8BfgPY4r4nSRPTHIg8AbgvKbcHZOyB+2k6m3Ak5Zo3p4MfqL6epLHJPkDFh/5LBUYjgEuXGIf\nSXOgzwHgXOD45sOeqvoC8F+AixmcPfPJRV476gnAWcA9wJeAu4F3Ndvew+AD+E7gHOAvx7z+74DP\nANcAHwN2nNd/ILAF2LqTev8r8O+SfD3Jac1zo0HrouZ2S9O27wJfWeS97HQiPMljgRcB/32R10ua\nE0teCJbkbOAlwLaqOmzM9n0YfKj9BLAr8O6q+vP2m9q+5lTKu6rqvWvYhocYnD30xTHbfo9B+86a\nfsseKclvAAdU1ZvXui2SVm+SAPAc4NvAuTsJAKcCj62qU5qraz8PbKiqH3TR4PVmsQAgSV1a8ieg\nqrqMwRkzO3MnD/+mvCfwdT/8l6Wfa3FIWnOPaqGMs4CLk9zB4HTBE1ooszeqqtXlGiRpUm1MAp8C\nXF9V+wHPAE5f5jnwkqQ10MYI4GiaJRGq6rYkXwIOAT49umMSf+5QJ6pqpdc1SL016Qgg7Pz88JsY\nrBlDkg0MLq7a6YRmVXV6O/XUU62jZ3VIWpklRwBJPszggql9knyZwQVSjwGqqs4E/hg4J8n1DILE\nG6vqnu6aLElqw5IBoKpOWmL73cDPt9YiSdJUrLsrgTdt2mQdPatD0spMNSXkYKVkf7NVu5JQTgJL\ny7buRgCSpMkYACSppwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPbVkAEhydpJtSW5YZJ9NSa5N8tkk\nl7TbRElSF9rICLYXcDnwgqrammTfZnmIcWV5IZha54Vg0sq0kRHsJOBvqmprs//YD39J0mxpYw7g\nacDeSS5JcnWSk1soU5LUsTYSwjwKeCZwLLA7cEWSK6rq1hbKliR1pI0A8FXg7qq6H7g/ySeAw4Gx\nAWDTpk1s3LiRjRs3smnTJleL1LJt3ryZzZs3s2XLFrZs2bLWzZHm1kSrgSbZCHysqg4ds+0Q4H3A\nccBuwFXACVX1uTH7Ogms1jkJLK3MqjOCVdXNSS4CbgAeBM4c9+EvSZot5gPQ3HMEIK2MVwJLUk8Z\nACSppwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBIUk+1khGs2e/ZSbYneXl7zZMkdWWS\nEcA5wAsX2yHJLsA7gYvaaJQkqXttZAQDeB3wUeCuNholSerequcAkuwHvKyqPgi4IJckzYk2JoFP\nA9409NggIElzoI2MYM8CzksSYF/g+CTbq+r8cTubEUyrZUYwqR2rzgg2st85zX5/u5Pt5gNQ68wH\nIK3MqjOCjezup7skzQkzgmnuOQKQVsYrgSWppwwAktRTBgBJ6ikDgCT1lAFAknrKACBJPWUAkKSe\nMgB0aGFhI0mWddt1192Xtf/Cwsa1fpuS5pQXgnVosDzSct/vcl8T+vQ3HccLwaSVWXVGsCQnJbm+\nuV2WZNH1giRJs6GNjGBfBJ5bVYcDbwPOaqNhkqRuLbkYXFVdluTgRbZfOfTwSmD/NhomSepW25PA\nrwYubLlMSVIH2kgIA0CS5wGvAp7TVpmSpO60EgCSHAacCRxXVYsmkDcjmFbLjGBSO1adESzJQcDF\nwMkj8wHjyvE00KVftczXeBqop4FKK7NkABjOCAZsYyQjWJKzgJcDtzP49NpeVUfupCwDwNKvWuZr\nDAAGAGllvBCsQwaA6TAASCvjUhCS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmn\nDACS1FOrzgjW7PPeJF9Icl2SI9ptoiSpC6vOCJbkeODJVfVU4DXAGS21TZLUoSUDQFVdBiy2xPNL\ngXObfa8C9kqyoZ3mSZK60sYcwP7AV4Yeb8W0kJI085wElqSeaiMj2FbgwKHHBzTPjWVGMK2WGcGk\ndrSREexFwGur6sVJjgJOq6qjdlKO+QCWftUyX2M+APMBSCuz5AhgOCNYki8zkhGsqi5I8qIktwLf\nYZAYXpI048wI1iFHANPhCEBaGSeBJamnDACS1FMGAEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhS\nTxkAJKmnJgoASY5LcnOSW5K8acz2fZJc2GQEuzHJK1tvqSSpVUsuBZFkF+AW4PnAHcDVwC9X1c1D\n+5wKPLaqTkmyL/B5YENV/WCkLJeCWPpVy3yNS0G4FIS0MpOMAI4EvlBVt1fVduA8BlnAht0J7Nnc\n3xP4+uiHvyRptkySD2A049dXGQSFYWcBFye5A9gDOKGd5kmSutLWJPApwPVVtR/wDOD0JHu0VLYk\nqQOTjAC2AgcNPR6X8eto4O0AVXVbki8BhwCfHi3MjGBaLTOCSe2YZBJ4VwaTus8HvgZ8Cjixqm4a\n2ufdwH1V9dYkGxh88B9eVfeMlOUk8NKvWuZrnAR2ElhamSVHAFX1YJLfAP6BwU9GZ1fVTUleQ5MV\nDPhj4Jwk1zP4BHvj6Ie/JGm2mBGsQ44ApsMRgLQyXgksST1lAJh7u5Fk4tvCwsa1brCkGeFPQB2a\n1k9Aff/JyJ+ApJVxBCBJPWUAkKSeMgBIUk8ZACSppwwAktRTBgBJ6qlWMoI1+2xKcm2Szya5pN1m\nSpLa1lZGsL2Ay4EXVNXWJPtW1d1jyvI6gKVftczXeB2A1wFIK9NWRrCTgL+pqq0A4z78JUmzZZIA\nMC4j2P4j+zwN2DvJJUmuTnJyWw2UJHVjkoQwk5bzTOBYYHfgiiRXVNWtLZUvSWpZWxnBvgrcXVX3\nA/cn+QRwOPCIAGBGMK2WGcGkdrSVEewQ4H3AccBuwFXACVX1uZGynARe+lXLfI2TwE4CSyvTSkaw\nqro5yUXADcCDwJmjH/6SpNnictAdcgQwHY4ApJXxSmBJ6ikDgCT1lAFAknrKACBJPWUAkKSeMgBI\nUk8ZACSppwwAktRTBgBJ6qnWMoI1+z07yfYkL2+viZKkLiwZAJqMYO8HXgj8NHBis/jbuP3eCVzU\ndiMlSe1rKyMYwOuAjwJ3tdg+SVJHWskIlmQ/4GVV9UEGq5NJkmZcW5PApwHDcwMGAUmacW1lBHsW\ncF4G6x/vCxyfZHtVnT9amBnBtFpmBJPa0UpGsJH9zwE+VlV/O2ab+QCWftUyX2M+APMBSCvTSkaw\n0Zd00E5JUsvMCNYhRwDT4QhAWhmvBJaknjIASFJPGQAkqacMAJLUUwaA3tmNJMu6LSxsXOtGS+qA\nZwF1aFbPAlpJm2b5/82zgKSVcQSwDAsLG5f1zVmSZpkjgGVY/jd6RwDT4AhAWhlHAJLUU61kBEty\nUpLrm9tlSQ5tv6mSpDa1lRHsi8Bzq+pw4G3AWW03VJLUrlYyglXVlVX1zebhlYwkjJEkzZ5WMoKN\neDVw4WoaJUnq3iQJYSaW5HnAq4DntFmuJKl9bWUEI8lhwJnAcVV1784KMyOYVsuMYFI7WskIluQg\n4GLg5Kq6cpGyvA6g9dd4HYDXAUgr01ZGsN8H9gY+0OQF3l5VR3bZcEnS6ngl8DI4AphNjgCklfFK\nYEnqKQOAJPWUAUCSesoAIEk9ZQCQpJ4yAEhSTxkAJKmneh0ATPE4qeUlkjeJvDQfen0hWPcXdq2f\nC8GWW8eUjysvBJNWoJWMYM0+703yhSTXJTmi3WZKktrWSkawJMcDT66qpwKvAc7ooK0T2bx58zRq\nsY5Ja5jK/4eklWglI1jz+FyAqroK2CvJhlZbOiEDwGzVYQCQZldbGcFG99k6Zh9J0gyZybOAPvnJ\nTy7rrJMkPP7xe5OEt771rZ7VI0kTmCQhzFHAH1bVcc3jNzPIA/AnQ/ucAVxSVR9pHt8MHFNV20bK\nmp1TgLSueBaQtHyTpIS8GnhKkoMZZAT7ZeDEkX3OB14LfKQJGN8Y/fAHO6kkzZJWMoJV1QVJXpTk\nVuA7DBLDS5Jm2FQvBJMkzY6ZnASWJHXPACBJPTXJJPDMay4623HdwdZxE9At17d3Vd3TQbm+j5XV\n18n7kNa7aS8G12pHbdYcOgPYi8HFZwAHAN8Afr2qrmmhjrdU1dua+08H/hfwaAYrpJ3QXPm82jp8\nH5PX0fn7kHqjqjq5AW8Zuv904BbgS8AW4F+3VMd148oCjgKub6mOa4bufxw4vrl/JHC572P9vQ9v\n3vpy63IO4OVD998FvKGqfhL4JeA9LdWxe435xldVVwK7t1THsP2r6sKmjk8Bj2upXN/HynT1PqRe\nmNYcwI901CRtddQLk3ycwUJ0O9YiOhB4BfD3LdXxpCTnM/iJ4YAkj6+q7zbbHt1SHb6PyU3jfUi9\n0GUA6LyjVtXrm6WoX8rQpCNwelVd0EYdPHLl013ghxOdH2yjAt/HsnT+PqS+6GwSOMkxI099pqq+\n3XTUX6yq0zupWJI0kc7mAKrq0pHbt5vnt03jwz/Jr1mHdUjauTW5EGxKHXUaC89ZR//qkNaNtboS\nuLWOmuSQJM9PssfIptvnrI6jm/PaSXJMkt9K8vyq+rN5qmNMnTsyxc11HdJ6tCaLwSV5VVWd00I5\nr2ewDPVNwBEMTjX9u2bbNVX1zDmp4x3AsQwC8mbguQzOcf854Pyq+tM5qeP80aeA5wH/CFBVvzAP\ndUh9sVYB4MtVdVAL5dwI/Jtmcnkj8FHgL6rqvya5tqqeMSd1/DNwGLAbcCdwQFXd15wue2VVHT4n\ndVwDfA74b0Ax+HD+HwxySFBVl85DHVJfdHYaaJIbdrYJaCth/C5Dk8tbkmwCPtokr2nrZ6Zp1PH9\nqnoQ+G6S26rqvqa+7yV5aI7qeBbwBuD3gN+pquuSfK/lD+Vp1CH1QpfXAWwAXgjcO/J8gMtbqmNb\nkiOq6jqA5lv6S4APAYfOUR3fH7pO4md2PJlkLwbfcueijqp6CHhPkr9u/t1Gy8fYNOqQ+qLL6wDO\nBs6pqsvGbPtwVZ3UQh0HAD+oqjvHbDu6qv5pTurYraoeGPP8vsBPVNWN81DHmLJfDBxdVb/bdtnT\nrENar8wIJkk9ZUIYSeopA4Ak9ZQBQJJ6ygAgST1lAJCknvr/AY4WOoIErCfyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f330710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alldatadf[[\"judgement\", \"dataset\", \"review_log_len\"]].\\\n",
    "    hist(by = [\"judgement\", \"dataset\"], figsize = (6,12),\n",
    "         sharey=True, normed=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through a data frame\n",
    "\n",
    "data frames have property\n",
    "\n",
    "    df.iterrows() # for rows\n",
    "    \n",
    "and\n",
    "\n",
    "    df.items()    # for columns\n",
    "\n",
    "you probably will need the former more often. And don't forget about `.apply`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for key, value in alldatadf.iterrows():\n",
    "    print(key)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "judgement\n",
      "internal_id\n",
      "stars\n",
      "review\n",
      "review_len\n",
      "review_log_len\n"
     ]
    }
   ],
   "source": [
    "for key, value in alldatadf.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000128951115312\n",
      "[-0.1476958]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "X = alldatadf[\"review_log_len\"].as_matrix().reshape(-1, 1)\n",
    "y = alldatadf[\"stars\"]\n",
    "mo = linear_model.LinearRegression()\n",
    "mo.fit(X, y)\n",
    "print(mo.score(X, y))\n",
    "print(mo.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUKqy1JoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1246756d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y, color = (1,0,0,.1))\n",
    "x_ = np.r_[min(X), max(X)]\n",
    "plt.plot(x_, mo.intercept_ + mo.coef_*x_, \"b-\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12714"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodbad = pd.concat([alldatadf[\"review\"].map(lambda x : \"good\" in x),\n",
    "           alldatadf[\"review\"].map(lambda x : \"bad\" in x)], \n",
    "          keys = [\"good\", \"bad\"],\n",
    "         join=\"inner\",\n",
    "        axis=1)\n",
    "\n",
    "goodbad.all(axis=1).sum() / goodbad.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldatadf[[\"judgement\", \"dataset\", \"review_len\"]].groupby([\"judgement\", \"dataset\"]).hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(alldatadf[\"stars\"].dtype)\n",
    "alldatadf[\"stars\"] = alldatadf[\"stars\"].astype(int)\n",
    "print(alldatadf[\"stars\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     50000\n",
       "1     10122\n",
       "2      4586\n",
       "3      4961\n",
       "4      5331\n",
       "7      4803\n",
       "8      5859\n",
       "9      4607\n",
       "10     9731\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[\"stars\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     10122\n",
       "2      4586\n",
       "3      4961\n",
       "4      5331\n",
       "7      4803\n",
       "8      5859\n",
       "9      4607\n",
       "10     9731\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[\"stars\"][alldatadf[\"judgement\"]!=\"unsup\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1088a66a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10891da20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alldatadf[\"stars\"][alldatadf[\"judgement\"]!=\"unsup\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>internal_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judgement</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">neg</th>\n",
       "      <th>test</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pos</th>\n",
       "      <th>test</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsup</th>\n",
       "      <th>train</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   internal_id  stars  review\n",
       "judgement dataset                            \n",
       "neg       test           12500  12500   12500\n",
       "          train          12500  12500   12500\n",
       "pos       test           12500  12500   12500\n",
       "          train          12500  12500   12500\n",
       "unsup     train          50000  50000   50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.groupby([\"judgement\", \"dataset\"]).agg(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "judgement  dataset\n",
       "neg        test       2.22312\n",
       "           train      2.21696\n",
       "pos        test       8.80280\n",
       "           train      8.73848\n",
       "unsup      train      0.00000\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.groupby([\"judgement\", \"dataset\"]).agg(np.mean)[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "test     5.512960\n",
       "train    1.825907\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf.groupby([\"dataset\"]).agg(np.mean)[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "test     5.51296\n",
       "train    5.47772\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldatadf[alldatadf[\"judgement\"]!=\"unsup\"].groupby([\"dataset\"]).agg(np.mean)[\"stars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"remove unsupervised data points\"\n",
    "alldatadf = alldatadf[(alldatadf[\"judgement\"]!=\"unsup\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"replace textual judgement label by a binary/boolean label\"\n",
    "alldatadf[\"positive_judgement\"] = alldatadf[\"judgement\"] == \"pos\"\n",
    "alldatadf.drop(\"judgement\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = alldatadf[(alldatadf[\"dataset\"] == \"train\")].copy()\n",
    "train_data.drop(\"dataset\", axis=1, inplace=True)\n",
    "# del alldatadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simple analysis with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "ngram_size = 3\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, ngram_size), min_df = .1, stop_words='english')\n",
    "# tokenizer=TreebankWordTokenizer().tokenize)\n",
    "\n",
    "classifier_pipeline = Pipeline([\n",
    "    ('count_vectorizer',   vectorizer),\n",
    "    ('classifier',         MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<20x361 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1090 stored elements in Compressed Sparse Row format>, dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams = vectorizer.fit_transform(train_data[:20].review.as_matrix())\n",
    "np.asarray(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "# y = train_data[:num_points][\"stars\"].as_matrix()\n",
    "y = shuffle(train_data[\"positive_judgement\"])[:num_points]#.as_matrix()\n",
    "X = train_data.loc[y.index.tolist()][\"review\"].as_matrix()\n",
    "# ngrams = vect.fit_transform(X)\n",
    "# KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate performance of the classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.91756272,  0.90473319,  0.92302281,  0.90372827,  0.90115807])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "cross_validation.cross_val_score(classifier_pipeline, X, y, cv = 5, scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model on the whole data set and inspect the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cntv = classifier_pipeline.get_params()[\"count_vectorizer\"]\n",
    "cl = classifier_pipeline.get_params()[\"classifier\"]\n",
    "model_analysis = pd.DataFrame({\"coef\": cl.coef_[0]}, index=cntv.get_feature_names()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>observed</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>533</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>3</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "observed   True   False\n",
       "predicted              \n",
       "True         533     15\n",
       "False          3    449"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "labels = [True, False]\n",
    "yhat = classifier_pipeline.predict(X)\n",
    "confmatr = pd.DataFrame(\n",
    "    metrics.confusion_matrix(yhat, y, labels=labels),\n",
    "    index = labels,\n",
    "    columns = labels\n",
    "    )\n",
    "confmatr.index.name = \"predicted\"\n",
    "confmatr.columns.name = \"observed\"\n",
    "confmatr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th>yhat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count\n",
       "y     yhat        \n",
       "False False    449\n",
       "      True      15\n",
       "True  False      3\n",
       "      True     533"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmatr = pd.DataFrame({\"yhat\":yhat, \n",
    "                         \"y\": y,\n",
    "                         \"count\":1}).groupby([\"y\", \"yhat\"]).agg(sum)\n",
    "confmatr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yhat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>449</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>15</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count      \n",
       "y     False True \n",
       "yhat             \n",
       "False   449     3\n",
       "True     15   533"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(confmatr.reset_index(), columns=\"y\", index=\"yhat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.62362112])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_analysis[\"voc\"] =  [cntv.vocabulary_[kk] for kk in model_analysis.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film bad</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look like citizen</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cliches</td>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clichd</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unoriginal</td>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lock</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seen long</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seen long time</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>load</td>\n",
       "      <td>movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lo</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            negative positive\n",
       "0           film bad     best\n",
       "1  look like citizen     just\n",
       "2            cliches   really\n",
       "3            clichd     time\n",
       "4         unoriginal    story\n",
       "5               lock     good\n",
       "6          seen long     like\n",
       "7     seen long time    great\n",
       "8               load    movie\n",
       "9                 lo     film"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntop = 10\n",
    "pd.DataFrame({\n",
    "            \"negative\": model_analysis[\"coef\"].sort_values()[:ntop].index,\n",
    "            \"positive\":model_analysis[\"coef\"].sort_values()[-ntop:].index\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_pipeline = Pipeline([\n",
    "    ('count_vectorizer',   vectorizer),\n",
    "    ('regression',         ElasticNetCV(l1_ratio=0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31265"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams = vectorizer.fit_transform(train_data[:2000].review.as_matrix())\n",
    "np.asarray(ngrams)\n",
    "valid = np.asarray(ngrams.sum(0)).ravel()>3\n",
    "print(valid.shape)\n",
    "print(valid.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngrams_selected = ngrams[:,np.where(valid)[-1]]\n",
    "# valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-6aa0769866e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1457\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1459\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 for train, test in folds)\n\u001b[1;32m   1166\u001b[0m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0;32m-> 1167\u001b[0;31m                              backend=\"threading\")(jobs)\n\u001b[0m\u001b[1;32m   1168\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;31m# X is copied and a reference is kept here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m     \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dlituiev/repos/scikit-learn/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sparse_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 max_iter, tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "cross_validation.cross_val_score(regression_pipeline, X, y, cv=5, scoring=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, category in enumerate(categories):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\"\n",
    "                      % (category, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=categories))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(loss='l2', penalty=penalty,\n",
    "                                            dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "  ('classification', LinearSVC())\n",
    "])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='r')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='g')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='b')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
